{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52116dac-ba26-428d-96b4-56f60f764fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage import filters, exposure\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import adjusted_rand_score, accuracy_score\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4926e1c9-6a10-4679-a297-ebbdb9d0f0af",
   "metadata": {},
   "source": [
    "# Partie 1 : Stratégie d’élaboration d’un modèle et traitement des images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eea657b-d4b7-400c-b456-3cba4567f167",
   "metadata": {},
   "source": [
    "## 1) Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c78ea7-c9cd-47f7-9bf4-986911fc7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'Flipkart/Images'\n",
    "csv_file = 'Flipkart/flipkart_com-ecommerce_sample_1050.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901d6685-c24c-4439-b0a0-c2b607aa3250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données du fichier CSV\n",
    "def load_data(csv_file):\n",
    "    data = pd.read_csv(csv_file, sep=\",\")\n",
    "    data = data[[\"uniq_id\", \"product_name\", \"product_category_tree\"]]\n",
    "    data[\"product_category_tree\"].replace(to_replace=r'[\\[\"\\]]', value=\"\", regex=True, inplace=True)\n",
    "    category = data[\"product_category_tree\"].str.split(\" >> \", expand=True)\n",
    "    category.rename(columns={0: \"Categorie\", 1: \"Sous-categorie 1\"}, inplace=True)\n",
    "    data = data.merge(category[[\"Categorie\", \"Sous-categorie 1\"]], how=\"inner\", on=category.index)\n",
    "    data['uniq_id_clean'] = data['uniq_id'].str.strip().str.lower()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab7bef7f-eb6d-4f60-9206-715d044a2cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hy/g05wz4ln30z1r5z3mv1rwd2h0000gn/T/ipykernel_67823/2919505949.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[\"product_category_tree\"].replace(to_replace=r'[\\[\"\\]]', value=\"\", regex=True, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Charger les données\n",
    "data = load_data(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33841e04-331c-4f48-8268-cec6ffa81cb6",
   "metadata": {},
   "source": [
    "## 2) Préparation des images avec des transformations améliorées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e625fd7e-1fe3-49aa-9561-e78b115dd7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert('L')  # Convertir en niveaux de gris\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # Réduire le bruit avec un filtre gaussien\n",
    "    img_filtered = filters.gaussian(img, sigma=1)\n",
    "    \n",
    "    # Améliorer le contraste avec l'égalisation d'histogramme\n",
    "    img_eq = exposure.equalize_hist(img_filtered)\n",
    "    \n",
    "    # Rééchelonner l'intensité pour étirer la plage dynamique\n",
    "    img_rescale = exposure.rescale_intensity(img_eq, in_range='image', out_range=(0, 255))\n",
    "    \n",
    "    return Image.fromarray(img_rescale.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d3a1a0-fab2-4bf7-9eaa-80e2751816a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lister les fichiers d'images\n",
    "image_files = os.listdir(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6b41ef1-1ee4-42de-b5d6-dd2c57563fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les images disponibles dans le dossier d'images\n",
    "image_files_no_ext = [os.path.splitext(file)[0].lower() for file in image_files]\n",
    "data = data[data['uniq_id_clean'].isin(image_files_no_ext)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261463f4-9507-4a35-98d7-e1a29701dfee",
   "metadata": {},
   "source": [
    "# Partie 2 : Séparation des ensembles d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb3ff048-74d0-4a74-8453-e1b7cc4b7a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des données en train/test (80% pour l'entraînement, 20% pour le test)\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42, stratify=data['Categorie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49e2bc7c-04d0-47cd-a1df-b5b58328dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des fichiers d'images pour chaque ensemble\n",
    "train_image_files = [f\"{file}.jpg\" for file in train_set['uniq_id_clean']]\n",
    "test_image_files = [f\"{file}.jpg\" for file in test_set['uniq_id_clean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667401fb-a912-41dd-b5b2-6c571d80e64d",
   "metadata": {},
   "source": [
    "# Partie 3 : Modèle simple (ORB) avec séparation train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7e70bf6-32a5-41b3-8d01-34f1b045b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des descripteurs ORB\n",
    "def extract_orb_features(image_files, image_folder):\n",
    "    all_descriptors = []\n",
    "    image_descriptors = []\n",
    "    for image_file in tqdm(image_files, desc=\"Extraction des descripteurs ORB\"):\n",
    "        img_path = os.path.join(image_folder, image_file)\n",
    "        img = preprocess_image(img_path)\n",
    "        \n",
    "        # Initialiser ORB\n",
    "        orb = cv2.ORB_create(nfeatures=500)  # Ajuster nfeatures pour détecter plus de points d'intérêt\n",
    "        \n",
    "        # Détecter les points d'intérêt et calculer les descripteurs\n",
    "        kp, des = orb.detectAndCompute(np.array(img), None)\n",
    "        \n",
    "        if des is not None:\n",
    "            des_mean = np.mean(des, axis=0)  # Prendre la moyenne des descripteurs\n",
    "            all_descriptors.append(des_mean)\n",
    "            image_descriptors.append(image_file)\n",
    "    \n",
    "    return np.array(all_descriptors), image_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65f59b73-751d-410d-9b70-bcd0d110c680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction des descripteurs ORB:  90%|████████▉ | 755/840 [01:20<00:05, 14.94it/s]/opt/anaconda3/envs/DS_PROJET_6/lib/python3.11/site-packages/PIL/Image.py:3368: DecompressionBombWarning: Image size (93680328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "Extraction des descripteurs ORB: 100%|██████████| 840/840 [01:33<00:00,  9.02it/s]\n",
      "Extraction des descripteurs ORB: 100%|██████████| 210/210 [00:22<00:00,  9.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extraction des features ORB pour train et test\n",
    "orb_features_train, orb_image_descriptors_train = extract_orb_features(train_image_files, image_folder)\n",
    "orb_features_test, orb_image_descriptors_test = extract_orb_features(test_image_files, image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efc3627c-40ef-42df-8965-4db68d720319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application du clustering et du t-SNE\n",
    "def apply_tsne_and_clustering(features, image_descriptors, n_clusters=7):\n",
    "    pca = PCA(n_components=20)\n",
    "    features_pca = pca.fit_transform(features)\n",
    "    \n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    features_tsne = tsne.fit_transform(features_pca)\n",
    "    \n",
    "    descriptors_tsne_df = pd.DataFrame(features_tsne, columns=['tsne1', 'tsne2'])\n",
    "    descriptors_tsne_df['image_file'] = image_descriptors\n",
    "    descriptors_tsne_df['image_file_no_ext'] = descriptors_tsne_df['image_file'].str.replace('.jpg', '').str.replace('.png', '').str.strip().str.lower()\n",
    "    \n",
    "    kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=0)\n",
    "    descriptors_tsne_df['kmeans_labels'] = kmeans.fit_predict(features_tsne)\n",
    "    \n",
    "    return descriptors_tsne_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7c99eb4-c661-42df-a877-aed4f70add8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DS_PROJET_6/lib/python3.11/site-packages/sklearn/manifold/_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/DS_PROJET_6/lib/python3.11/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Application du t-SNE et du clustering sur le jeu d'entraînement\n",
    "orb_descriptors_tsne_train = apply_tsne_and_clustering(orb_features_train, orb_image_descriptors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cacf075-6ad4-46f0-a4f6-fd7ba421faa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'ARI (Adjusted Rand Index)\n",
    "def calculate_ari(descriptors_tsne_df, data):\n",
    "    # Création d'un dictionnaire qui mappe chaque fichier d'image à sa vraie catégorie\n",
    "    file_to_category = {row['uniq_id_clean']: row['Categorie'] for _, row in data.iterrows()}\n",
    "    \n",
    "    # Associer les vraies catégories aux images en se basant sur le nom de fichier\n",
    "    descriptors_tsne_df['true_labels'] = descriptors_tsne_df['image_file_no_ext'].map(file_to_category)\n",
    "    \n",
    "    # Supprimer les lignes avec des valeurs manquantes (si certaines images ne sont pas dans le CSV par exemple)\n",
    "    descriptors_tsne_df = descriptors_tsne_df.dropna(subset=['true_labels'])\n",
    "    \n",
    "    # Encoder les vraies étiquettes sous forme numérique pour calculer l'ARI\n",
    "    label_encoder = LabelEncoder()\n",
    "    true_labels_encoded = label_encoder.fit_transform(descriptors_tsne_df['true_labels'])\n",
    "    \n",
    "    # Calcul de l'ARI entre les étiquettes réelles et les clusters prédits par KMeans\n",
    "    ari = adjusted_rand_score(true_labels_encoded, descriptors_tsne_df['kmeans_labels'])\n",
    "    \n",
    "    return ari, descriptors_tsne_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3bb2bb5-299b-4954-b8ab-b69a5bcb1b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI pour la méthode basique (ORB) sur le train_set : 0.03471815172401472\n"
     ]
    }
   ],
   "source": [
    "# Calcul de l'ARI pour ORB\n",
    "ari_orb_train, orb_descriptors_tsne_train = calculate_ari(orb_descriptors_tsne_train, train_set)\n",
    "print(f\"ARI pour la méthode basique (ORB) sur le train_set : {ari_orb_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e30102c6-fc3c-475e-9125-6015fadc43d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DS_PROJET_6/lib/python3.11/site-packages/sklearn/manifold/_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/DS_PROJET_6/lib/python3.11/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI pour la méthode basique (ORB) sur le test_set : 0.0032625344221608277\n"
     ]
    }
   ],
   "source": [
    "# Application du t-SNE et du clustering sur le jeu de test\n",
    "orb_descriptors_tsne_test = apply_tsne_and_clustering(orb_features_test, orb_image_descriptors_test)\n",
    "ari_orb_test, orb_descriptors_tsne_test = calculate_ari(orb_descriptors_tsne_test, test_set)\n",
    "print(f\"ARI pour la méthode basique (ORB) sur le test_set : {ari_orb_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5c4551-9a44-405b-9ea4-418ee8c47972",
   "metadata": {},
   "source": [
    "# Partie 4 : Modèle avancé (VGG16) avec Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "640dc0a6-4f05-4652-a1de-2959b4f09fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des features avec VGG16\n",
    "def extract_vgg16_features(image_files, image_folder):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
    "    images_features = []\n",
    "    image_descriptors = []\n",
    "    for image_file in tqdm(image_files, desc=\"Extraction des features VGG16\"):\n",
    "        img_path = os.path.join(image_folder, image_file)\n",
    "        image = load_img(img_path, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = preprocess_input(image)\n",
    "        features = base_model.predict(image, verbose=0)\n",
    "        images_features.append(features.flatten())\n",
    "        image_descriptors.append(image_file)\n",
    "    return np.array(images_features), image_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb566d3-f108-4150-b2b6-0abc2fbf09a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction des features VGG16:   0%|          | 0/840 [00:00<?, ?it/s]2024-10-10 08:38:44.123271: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "Extraction des features VGG16:  61%|██████▏   | 516/840 [01:33<00:47,  6.80it/s]"
     ]
    }
   ],
   "source": [
    "# Extraction des features VGG16 pour train et test\n",
    "vgg16_features_train, vgg16_image_descriptors_train = extract_vgg16_features(train_image_files, image_folder)\n",
    "vgg16_features_test, vgg16_image_descriptors_test = extract_vgg16_features(test_image_files, image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc285e4-81ea-414f-9809-b7c137968d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application du t-SNE et du clustering sur le jeu d'entraînement\n",
    "vgg16_descriptors_tsne_train = apply_tsne_and_clustering(vgg16_features_train, vgg16_image_descriptors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d0384a-7ec3-4a19-98a1-a9a74efe2039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'ARI pour VGG16 sur train_set\n",
    "ari_vgg16_train, vgg16_descriptors_tsne_train = calculate_ari(vgg16_descriptors_tsne_train, train_set)\n",
    "print(f\"ARI pour la méthode avancée (VGG16) sur le train_set : {ari_vgg16_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ee4eb-e271-4e38-bc0e-5da250a35e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application du t-SNE et du clustering sur le jeu de test\n",
    "vgg16_descriptors_tsne_test = apply_tsne_and_clustering(vgg16_features_test, vgg16_image_descriptors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc714932-a1f9-446e-9a22-87a7f4bffe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'ARI pour VGG16 sur test_set\n",
    "ari_vgg16_test, vgg16_descriptors_tsne_test = calculate_ari(vgg16_descriptors_tsne_test, test_set)\n",
    "print(f\"ARI pour la méthode avancée (VGG16) sur le test_set : {ari_vgg16_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2f4572-6679-4f79-864f-b96b32b07485",
   "metadata": {},
   "source": [
    "# Partie 5 : Visualisation des t-SNE pour ORB et VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe1b465-b875-4d8e-86e7-1c0375ea83cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation du t-SNE des clusters prédits par KMeans pour ORB\n",
    "def visualize_tsne(descriptors_tsne_df, method_name):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.scatterplot(x='tsne1', y='tsne2', hue='kmeans_labels', data=descriptors_tsne_df, palette='viridis')\n",
    "    plt.title(f't-SNE des descripteurs {method_name} avec K-Means (Labels Prédits)')\n",
    "    plt.xlabel('t-SNE Dimension 1')\n",
    "    plt.ylabel('t-SNE Dimension 2')\n",
    "    plt.show()\n",
    "\n",
    "    # Visualisation des vraies catégories\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.scatterplot(x='tsne1', y='tsne2', hue='true_labels', data=descriptors_tsne_df, palette='viridis')\n",
    "    plt.title(f't-SNE des descripteurs {method_name} avec K-Means (Vraies Catégories)')\n",
    "    plt.xlabel('t-SNE Dimension 1')\n",
    "    plt.ylabel('t-SNE Dimension 2')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef7781-58fc-4ae3-a03d-1ac299591818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des résultats t-SNE pour ORB\n",
    "print(\"\\nVisualisation t-SNE pour ORB\")\n",
    "visualize_tsne(orb_descriptors_tsne_test, 'ORB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e7363-0b72-4f3e-8358-1c83b8259938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des résultats t-SNE pour VGG16\n",
    "print(\"\\nVisualisation t-SNE pour VGG16\")\n",
    "visualize_tsne(vgg16_descriptors_tsne_test, 'VGG16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d9ce0b-ab73-416d-bef9-803cc4b01b43",
   "metadata": {},
   "source": [
    "# Partie 6 : Comparaison des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e53930-caef-4c2c-a52d-d763cc55c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des ARI entre les deux méthodes\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Méthode': ['Basique (ORB)', 'Avancée (VGG16)'],\n",
    "    'ARI Train': [ari_orb_train, ari_vgg16_train],\n",
    "    'ARI Test': [ari_orb_test, ari_vgg16_test]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f72e3-e64e-408d-9267-7d7a86810b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le tableau comparatif\n",
    "print(\"\\nTableau comparatif des résultats ARI :\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf482db9-b002-40b3-826b-41ca046ed83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation du tableau comparatif\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x='Méthode', y='ARI Test', data=comparison_df, palette='Blues_d')\n",
    "plt.title('Comparaison des ARI entre la méthode basique (ORB) et avancée (VGG16) sur le test_set')\n",
    "plt.ylabel('ARI (Test)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
